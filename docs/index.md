---
hide:
  - navigation
  #- toc # table of contents - menu da direita
---

# Projeto Sistema de Transportadora Inteligente

![Logo](images/logo.png)

## Introdução

Este projeto foi desenvolvido para implementar um sistema de gestão inteligente para uma transportadora, utilizando técnicas avançadas de Engenharia de Dados para otimizar operações logísticas e melhorar a eficiência de entregas, processos e de gerenciamento interno. A equipe aplicou ferramentas modernas e tecnologias como Python, PySpark, Delta Lake, e Databricks para construir uma robusta pipeline de dados.

## Objetivo

O objetivo principal deste projeto é desenvolver um sistema de gestão integrada para uma transportadora, utilizando engenharia de dados para otimizar operações logísticas. Isso inclui a coleta, armazenamento, transformação e análise de dados. A equipe buscará melhorar a eficiência na atribuição de motoristas e veículos, planejamento de rotas otimizado, gestão eficaz de cargas e melhor experiência para os clientes, garantindo entregas pontuais e seguras.


## Equipe

A equipe responsável pelo desenvolvimento deste projeto inclui:

- **Henrique Forgiarini** - *Coleta e integração de dados de rastreamento* - [Perfil GitHub](https://github.com/HenriqueSilva29)
- **Bruno Supriano** - *Armazenamento e gerenciamento de dados no Delta Lake* - [Perfil GitHub](https://github.com/BrunoSupriano)
- **Renato Ribas** - *Configuração e otimização do ambiente no Databricks* - [Perfil GitHub](https://github.com/RenatoRibas)
- **Tiago Salles** - *Desenvolvimento de modelos preditivos para gestão de frota* - [Perfil GitHub](https://github.com/TiagoS4)
- **João Pedro Cardoso** - *Análise de dados utilizando PySpark* - [Perfil GitHub](https://github.com/jpdarabas)
- **Diego Hahn** - *Orquestração de workflows no Databricks* - [Perfil GitHub](https://github.com/DiegoHahn)
- **Jhayne Henemam** - *Desenvolvimento de dashboards para visualização de dados* - [Perfil GitHub](https://github.com/JhayneK)
- **Keniel Alves** - *Gerenciamento de versionamento e documentação* - [Perfil GitHub](https://github.com/KenielDev)

## Pipeline de Engenharia de Dados

A pipeline desenvolvida neste projeto inclui as seguintes etapas:

1. **Coleta de Dados**: Utilização de uma biblioteca de inserção de dados fictícios (Faker).
2. **Armazenamento de Dados**: Utilização do Delta Lake para armazenar dados de forma escalável e confiável.
3. **Transformação de Dados**: Processamento de grandes volumes de dados utilizando PySpark no Databricks.
4. **Análise de Dados**: Utilização de notebooks interativos no Databricks para análise preditiva e otimização de rotas.
5. **Automação e Orquestração**: Orquestração de workflows no Databricks para automatizar processos de ingestão, transformação e análise de dados.

## Tecnologias Utilizadas

Além das tecnologias mencionadas, este projeto também fez uso extensivo das capacidades do Databricks para processamento de big data em tempo real e colaboração em equipe.

## Conclusão

Este projeto não apenas demonstra a aplicação prática dos conceitos de Engenharia de Dados, mas também oferece uma solução inovadora para melhorar a eficiência e a competitividade de uma transportadora. A equipe está entusiasmada em contribuir para um projeto que pode transformar positivamente a logística de transporte de cargas.



---

<div style="text-align: center;">
    <b>Copyright &copy; 2024 - <a href="#" target="_blank">Jorge Luiz da Silva</a> - Todos os direitos reservados.</b>
</div>
